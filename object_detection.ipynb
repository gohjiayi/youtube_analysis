{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection of YouTube Thumbnails\n",
    "This notebook aims to download all thumbnail images and to run yolov3 object detection model to detect the presence of, and the number of humans in an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed\n"
     ]
    }
   ],
   "source": [
    "# Change to your own directory\n",
    "try: \n",
    "    os.chdir(\"C:/Users/Jiayi/Documents/GitHub/youtube_analysis\")\n",
    "    print(\"Directory changed\")\n",
    "except OSError:\n",
    "    print(\"Can't change the Current Working Directory\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Thumbnail Images (locally)\n",
    "All 400k images are downloaded into my local computer and it took roughly 20 hours to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_df = pd.read_csv('data/videos_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408690, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelId</th>\n",
       "      <th>description</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>videoId</th>\n",
       "      <th>thumbnails</th>\n",
       "      <th>videoTitle</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>dislikeCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>viewCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCjOl2AUblVmg2rA_cRgZkFg</td>\n",
       "      <td>In this week's Top Gear, Flintoff gets his han...</td>\n",
       "      <td>2020-10-09 09:35:54</td>\n",
       "      <td>NXX338WY_Lw</td>\n",
       "      <td>https://i.ytimg.com/vi/NXX338WY_Lw/default.jpg</td>\n",
       "      <td>PREVIEW: Attempting 200mph in the Jaguar XJ220...</td>\n",
       "      <td>528.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>5819.0</td>\n",
       "      <td>184447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCjOl2AUblVmg2rA_cRgZkFg</td>\n",
       "      <td>From the humble new Volkswagen GTI, right down...</td>\n",
       "      <td>2020-10-09 11:21:23</td>\n",
       "      <td>dtHcdU2c71Y</td>\n",
       "      <td>https://i.ytimg.com/vi/dtHcdU2c71Y/default.jpg</td>\n",
       "      <td>Which car will win Top Gear Speed Week 2020? (...</td>\n",
       "      <td>568.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7136.0</td>\n",
       "      <td>217619.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCjOl2AUblVmg2rA_cRgZkFg</td>\n",
       "      <td>Here's Chris Harris' take on the rocket-disgui...</td>\n",
       "      <td>2020-10-07 07:40:22</td>\n",
       "      <td>vnrtWe-RAzg</td>\n",
       "      <td>https://i.ytimg.com/vi/vnrtWe-RAzg/default.jpg</td>\n",
       "      <td>Chris Harris on... the Ferrari SF90 Stradale |...</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>10189.0</td>\n",
       "      <td>437777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCjOl2AUblVmg2rA_cRgZkFg</td>\n",
       "      <td>16 contenders, 8,553bhp and a festival to reme...</td>\n",
       "      <td>2020-10-06 13:59:38</td>\n",
       "      <td>Ra1F0TsOCPs</td>\n",
       "      <td>https://i.ytimg.com/vi/Ra1F0TsOCPs/default.jpg</td>\n",
       "      <td>Chris Harris vs 2020’s Best Performance Cars |...</td>\n",
       "      <td>579.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>7126.0</td>\n",
       "      <td>191070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCjOl2AUblVmg2rA_cRgZkFg</td>\n",
       "      <td>The 986bhp Ferrari SF90 is, unsurprisingly, no...</td>\n",
       "      <td>2020-10-06 07:36:13</td>\n",
       "      <td>fXysipmTxcQ</td>\n",
       "      <td>https://i.ytimg.com/vi/fXysipmTxcQ/default.jpg</td>\n",
       "      <td>FASTEST TOP GEAR LAP? Ferrari SF90 Stiglap | T...</td>\n",
       "      <td>888.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>9697.0</td>\n",
       "      <td>572569.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  channelId  \\\n",
       "0  UCjOl2AUblVmg2rA_cRgZkFg   \n",
       "1  UCjOl2AUblVmg2rA_cRgZkFg   \n",
       "2  UCjOl2AUblVmg2rA_cRgZkFg   \n",
       "3  UCjOl2AUblVmg2rA_cRgZkFg   \n",
       "4  UCjOl2AUblVmg2rA_cRgZkFg   \n",
       "\n",
       "                                         description          publishedAt  \\\n",
       "0  In this week's Top Gear, Flintoff gets his han...  2020-10-09 09:35:54   \n",
       "1  From the humble new Volkswagen GTI, right down...  2020-10-09 11:21:23   \n",
       "2  Here's Chris Harris' take on the rocket-disgui...  2020-10-07 07:40:22   \n",
       "3  16 contenders, 8,553bhp and a festival to reme...  2020-10-06 13:59:38   \n",
       "4  The 986bhp Ferrari SF90 is, unsurprisingly, no...  2020-10-06 07:36:13   \n",
       "\n",
       "       videoId                                      thumbnails  \\\n",
       "0  NXX338WY_Lw  https://i.ytimg.com/vi/NXX338WY_Lw/default.jpg   \n",
       "1  dtHcdU2c71Y  https://i.ytimg.com/vi/dtHcdU2c71Y/default.jpg   \n",
       "2  vnrtWe-RAzg  https://i.ytimg.com/vi/vnrtWe-RAzg/default.jpg   \n",
       "3  Ra1F0TsOCPs  https://i.ytimg.com/vi/Ra1F0TsOCPs/default.jpg   \n",
       "4  fXysipmTxcQ  https://i.ytimg.com/vi/fXysipmTxcQ/default.jpg   \n",
       "\n",
       "                                          videoTitle  commentCount  \\\n",
       "0  PREVIEW: Attempting 200mph in the Jaguar XJ220...         528.0   \n",
       "1  Which car will win Top Gear Speed Week 2020? (...         568.0   \n",
       "2  Chris Harris on... the Ferrari SF90 Stradale |...        1091.0   \n",
       "3  Chris Harris vs 2020’s Best Performance Cars |...         579.0   \n",
       "4  FASTEST TOP GEAR LAP? Ferrari SF90 Stiglap | T...         888.0   \n",
       "\n",
       "   dislikeCount  likeCount  viewCount  \n",
       "0         257.0     5819.0   184447.0  \n",
       "1         273.0     7136.0   217619.0  \n",
       "2         408.0    10189.0   437777.0  \n",
       "3         202.0     7126.0   191070.0  \n",
       "4         168.0     9697.0   572569.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Checking if there are duplicate videoId\n",
    "print(videos_df['videoId'].duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading thumbnail images \n",
    "videocount = len(videos_df)\n",
    "errors_videoId = []\n",
    "\n",
    "if not os.path.exists('images'):\n",
    "    print(\"Creating images folder\")\n",
    "    os.makedirs('images')\n",
    "\n",
    "for index, row in videos_df.iterrows():\n",
    "    url = row['thumbnails']\n",
    "    filename = 'images/' + row['videoId'] + '.jpg'\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        #print(\"[\" + str(index+1) + \"/\" + str(videocount) + \"] \" + filename + \" already exists\")\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "        except Exception as e:\n",
    "            #print(\"[\" + str(index+1) + \"/\" + str(videocount) + \"] \" + str(e))\n",
    "            errors_videoId.append(row['videoId'])\n",
    "            continue\n",
    "        print(\"[\" + str(index+1) + \"/\" + str(videocount) + \"] \" + filename + \" saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_videoId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors_videoId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Object Detection Model (Locally)\n",
    "Only recommend running object detection locally if there are high computational specs. Estimated to take at least 8 days to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load YOLO\n",
    "net = cv2.dnn.readNet(\"models/object_detection/yolov3.weights\",\"models/object_detection/yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"models/object_detection/coco.names\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = net.getLayerNames()\n",
    "outputlayers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagecount = 0\n",
    "rows = []\n",
    "\n",
    "for filename in os.listdir('images'):\n",
    "    if filename.endswith(\".jpg\"): # Omit non-images files\n",
    "        imagecount += 1\n",
    "        itemcount = 0\n",
    "        itemdict = {}\n",
    "        img = cv2.imread(\"images/\" + filename)\n",
    "        print(\"Image [\" + str(imagecount) + \"]: \" + filename)\n",
    "        \n",
    "        blob = cv2.dnn.blobFromImage(img,0.00392,(416,416),(0,0,0),True,crop=False)\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Detecting Objects\n",
    "        outs = net.forward(outputlayers)\n",
    "        # Saving item detected\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    itemcount += 1\n",
    "                    \n",
    "                    itemdict[class_id] = (itemdict[class_id] + 1 if class_id in itemdict else 1)\n",
    "                    \n",
    "        rows.append([filename[:-4], itemcount, itemdict])\n",
    "        print(\"Item Count: \" + str(itemcount) + \", Item Dict: \" + str(itemdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detection_df = pd.DataFrame(rows, columns=[\"videoId\", \"itemCount\", \"itemDict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detection_df.to_csv('data/object_detection_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Thumbnail Images (AWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could have been further simplified if a script was written to scrape from the URLs directly into AWS S3.\n",
    "\n",
    "In this case, to upload thumbnail images locally to AWS S3, install AWS CLI on your computer first. Then, check if it has been installed by running `aws --version` on your command prompt. Insert your AWS credentials by running `aws configure`, and check if it has been saved correctly by running `aws configure list`. <br>\n",
    "\n",
    "Once that has been set up, navigate to the folder of images. In my case, the command used is: `cd [path]/youtube_analysis/images`. I have created an accesspoint on AWS S3 and I will be able to upload the all images in the folder by running the following command `aws s3 cp . s3://[amazon resource name (ARN)]:accesspoint/[accesspoint name]/[bucket folder] --recursive`.\n",
    "\n",
    "The upload of these photos took about 6-8 hours, faster methods such as s3-parallel-put can be explored as an alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Object Detection Model (AWS)\n",
    "Using a ml.m5.24xlarge notebook instance, it took roughly 36 hours to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import subprocess as sb\n",
    "import tarfile\n",
    "from io import BytesIO\n",
    "import csv\n",
    "\n",
    "import boto3\n",
    "import gluoncv # !pip install gluoncv\n",
    "from gluoncv import model_zoo, data, utils\n",
    "from matplotlib import pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, image, nd\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.mxnet.model import MXNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Bucket\n",
    "s3_bucket = 'sagemaker-us-east-2-281536989307'\n",
    "print('Using bucket: ' + s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download yolov3 model for use\n",
    "model_name = 'yolo3_darknet53_coco'\n",
    "net = model_zoo.get_model(model_name, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the detector to the \"person\" class only\n",
    "# By default the model will have 80 classes from coco.names in net.classes but they are not needed\n",
    "classes = ['person']\n",
    "net.reset_class(classes=classes, reuse_weights=classes)\n",
    "print('New classes: ', net.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.hybridize()  # Hybridize to optimize computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Paginator to iterate through files in S3 Folder\n",
    "image_folder = 'A0185610J/images'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket=s3_bucket, Prefix=image_folder)\n",
    "\n",
    "errors = [] # To note if errors occur\n",
    "\n",
    "# Adding humanCount Column\n",
    "with open('data/object_detection_df.csv', \"w\", newline='\\n') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow(['videoId', 'humanCount'])\n",
    "\n",
    "    for page in pages:\n",
    "        for obj in page['Contents']:\n",
    "            image_path = obj['Key']\n",
    "            if image_path.endswith('.jpg'): # Omit non-images files and the main file name\n",
    "                s3_key = image_path\n",
    "                videoId = str(image_path.split('/')[-1].split('.')[0])\n",
    "\n",
    "                try:\n",
    "                    with BytesIO() as f:\n",
    "                        boto3.client(\"s3\").download_fileobj(Bucket=s3_bucket, Key=s3_key, Fileobj=f)\n",
    "                        f.seek(0)\n",
    "                        img = plt.imread(f, format='jpg')\n",
    "                        #plt.imshow(img) #to show the image\n",
    "\n",
    "                        im_array_mx = mx.ndarray.array(img)\n",
    "                        x, orig_img = data.transforms.presets.yolo.transform_test(im_array_mx)\n",
    "\n",
    "                        box_ids, scores, bboxes = net(x)\n",
    "\n",
    "                        # Convert to numpy array and removing undetected rows (default -1)\n",
    "                        scores = scores[0].asnumpy()\n",
    "                        scores = scores[(scores != -1)]\n",
    "\n",
    "                        humanCount = str(len([e for e in scores if e > 0.2])) #Threshold of 0.2 probability\n",
    "\n",
    "                        writer.writerow([videoId, humanCount]) # Input in csv file format\n",
    "                        f.close()\n",
    "                except:\n",
    "                    errors.append(videoId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of disconnection, run this code that allows continuation of progress\n",
    "\n",
    "# # Initiate Paginator to iterate through files in S3 Folder\n",
    "# image_folder = 'A0185610J/images'\n",
    "\n",
    "# s3 = boto3.client('s3')\n",
    "# paginator = s3.get_paginator('list_objects_v2')\n",
    "# pages = paginator.paginate(Bucket=s3_bucket, Prefix=image_folder)\n",
    "\n",
    "# errors = [] # To note if errors occur\n",
    "# df = pd.read_csv('data/object_detection_df.csv') # continuation\n",
    "# savedVideoId = df['videoId'].values # continuation\n",
    "\n",
    "# with open('data/object_detection_df.csv', \"a\", newline='\\n') as csv_file: # continuation\n",
    "#     writer = csv.writer(csv_file, delimiter=',')\n",
    "#     #writer.writerow(['videoId', 'humanCount']) # continuation\n",
    "\n",
    "#     for page in pages:\n",
    "#         for obj in page['Contents']:\n",
    "#             image_path = obj['Key']\n",
    "#             if image_path.endswith('.jpg'): # Omit non-images files and the main file name\n",
    "#                 videoId = str(image_path.split('/')[-1].split('.')[0])\n",
    "                \n",
    "#                 if videoId in savedVideoId: # skip processed videos, continuation\n",
    "#                     continue\n",
    "                \n",
    "#                 try:\n",
    "#                     with BytesIO() as f:\n",
    "#                         boto3.client(\"s3\").download_fileobj(Bucket=s3_bucket, Key=image_path, Fileobj=f)\n",
    "#                         f.seek(0)\n",
    "#                         img = plt.imread(f, format='jpg')\n",
    "#                         #plt.imshow(img) #to show the image\n",
    "\n",
    "#                         im_array_mx = mx.ndarray.array(img)\n",
    "#                         x, orig_img = data.transforms.presets.yolo.transform_test(im_array_mx)\n",
    "\n",
    "#                         box_ids, scores, bboxes = net(x)\n",
    "\n",
    "#                         # Convert to numpy array and removing undetected rows (default -1)\n",
    "#                         scores = scores[0].asnumpy()\n",
    "#                         scores = scores[(scores != -1)]\n",
    "\n",
    "#                         humanCount = str(len([e for e in scores if e > 0.2])) #Threshold of 0.2 probability\n",
    "\n",
    "#                         writer.writerow([videoId, humanCount]) # Input in csv file format\n",
    "#                         f.close()\n",
    "#                 except:\n",
    "#                     errors.append(videoId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding humanPresence Column\n",
    "object_detection_df = pd.read_csv('data/object_detection_df.csv')\n",
    "object_detection_df['humanPresence'] = np.where(df['humanCount'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>humanCount</th>\n",
       "      <th>humanPresence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---E9WQc-78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---M5RE8nJo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--0xL_wWq_0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--19fKTapfY</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--2dRWL5rjE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId  humanCount  humanPresence\n",
       "0  ---E9WQc-78           2              1\n",
       "1  ---M5RE8nJo           1              1\n",
       "2  --0xL_wWq_0           2              1\n",
       "3  --19fKTapfY           2              1\n",
       "4  --2dRWL5rjE           0              0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_detection_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detection_df.to_csv('data/object_detection_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
