{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"youtube\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by importing SparkSession, which is our new API in Spark for doing DataFrame adn DataSet operations.\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"YT\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "df = spark.read.csv(\"features_scaled_df.csv\",header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------+\n",
      "|features                                                                          |\n",
      "+----------------------------------------------------------------------------------+\n",
      "|(9,[0,1,2],[0.275,0.0656551412939252,0.014979859821399953])                       |\n",
      "|(9,[0,1,2],[0.375,0.0656551412939252,0.014979859821399953])                       |\n",
      "|(9,[0,1,2,3],[0.225,0.0656551412939252,0.014979859821399953,0.11764705882352941]) |\n",
      "|(9,[0,1,2,3],[0.3,0.0656551412939252,0.014979859821399953,0.058823529411764705])  |\n",
      "|(9,[0,1,2],[0.275,0.0656551412939252,0.014979859821399953])                       |\n",
      "|(9,[0,1,2],[0.275,0.0656551412939252,0.014979859821399953])                       |\n",
      "|(9,[0,1,2],[0.375,0.0656551412939252,0.014979859821399953])                       |\n",
      "|(9,[0,1,2],[0.425,0.0656551412939252,0.014979859821399953])                       |\n",
      "|(9,[0,1,2],[0.425,0.0656551412939252,0.014979859821399953])                       |\n",
      "|(9,[0,1,2,3],[0.45,0.0656551412939252,0.014979859821399953,0.058823529411764705]) |\n",
      "|(9,[0,1,2],[0.225,0.0656551412939252,0.014979859821399953])                       |\n",
      "|(9,[0,1,2,3],[0.35,0.0656551412939252,0.014979859821399953,0.058823529411764705]) |\n",
      "|(9,[0,1,2],[0.17500000000000002,0.0656551412939252,0.014979859821399953])         |\n",
      "|(9,[0,1,2],[0.325,0.0656551412939252,0.014979859821399953])                       |\n",
      "|(9,[0,1,2],[0.25,0.0656551412939252,0.014979859821399953])                        |\n",
      "|(9,[0,1,2,3],[0.225,0.0656551412939252,0.014979859821399953,0.058823529411764705])|\n",
      "|(9,[0,1,2,3],[0.375,0.0656551412939252,0.014979859821399953,0.11764705882352941]) |\n",
      "|(9,[0,1,2,3],[0.325,0.0656551412939252,0.014979859821399953,0.058823529411764705])|\n",
      "|(9,[0,1,2],[0.425,0.0656551412939252,0.014979859821399953])                       |\n",
      "|(9,[0,1,2],[0.3,0.0656551412939252,0.014979859821399953])                         |\n",
      "+----------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#transform to vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= ['titleLen', 'subscriberCount', 'avgViewCount', 'humanCount', 'HOW TO & STYLE', 'SPORTS', 'TRAVEL', 'Negative', 'titleINTJ'],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(df)\n",
    "output.select(\"features\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = output.withColumn(\"label\",output[\"viewCount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PolynomialExpansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyExpansion = PolynomialExpansion(degree=3, inputCol=\"features\", outputCol=\"polyFeatures\")\n",
    "polyDF = polyExpansion.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|    label|\n",
      "+--------------------+---------+\n",
      "|(219,[0,1,2,3,4,5...| 184447.0|\n",
      "|(219,[0,1,2,3,4,5...| 217619.0|\n",
      "|(219,[0,1,2,3,4,5...| 437777.0|\n",
      "|(219,[0,1,2,3,4,5...| 191070.0|\n",
      "|(219,[0,1,2,3,4,5...| 572569.0|\n",
      "|(219,[0,1,2,3,4,5...| 848767.0|\n",
      "|(219,[0,1,2,3,4,5...| 291800.0|\n",
      "|(219,[0,1,2,3,4,5...| 218842.0|\n",
      "|(219,[0,1,2,3,4,5...| 786868.0|\n",
      "|(219,[0,1,2,3,4,5...| 249576.0|\n",
      "|(219,[0,1,2,3,4,5...| 250697.0|\n",
      "|(219,[0,1,2,3,4,5...| 355497.0|\n",
      "|(219,[0,1,2,3,4,5...| 830987.0|\n",
      "|(219,[0,1,2,3,4,5...| 129057.0|\n",
      "|(219,[0,1,2,3,4,5...| 219546.0|\n",
      "|(219,[0,1,2,3,4,5...| 555464.0|\n",
      "|(219,[0,1,2,3,4,5...|1132180.0|\n",
      "|(219,[0,1,2,3,4,5...| 406073.0|\n",
      "|(219,[0,1,2,3,4,5...| 131059.0|\n",
      "|(219,[0,1,2,3,4,5...| 209937.0|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "polyData = polyDF.select([\"polyFeatures\",\"label\"]).withColumnRenamed(\"polyFeatures\", \"features\")\n",
    "polyData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingPolyData, testPolyData) = polyData.randomSplit([0.7, 0.3], seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# TrainValidationSplit will try all combinations of values and determine best model using\n",
    "# the evaluator.\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                      estimatorParamMaps=paramGrid,\n",
    "                      evaluator=RegressionEvaluator(),\n",
    "                      numFolds=2)  # use 3+ folds in practice\n",
    "\n",
    "#choose the best set of parameters.\n",
    "cvModel = crossval.fit(trainingPolyData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7f9e302b5488>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(cvModel.avgMetrics, paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LinearRegression_4ec4817545809e44dd6d', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2,\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.5,\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='epsilon', doc='The shape parameter to control the amount of robustness. Must be > 1.0.'): 1.35,\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='featuresCol', doc='features column name'): 'features',\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='fitIntercept', doc='whether to fit an intercept term'): False,\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='labelCol', doc='label column name'): 'label',\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='loss', doc='The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError)'): 'squaredError',\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='maxIter', doc='maximum number of iterations (>= 0)'): 100,\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='regParam', doc='regularization parameter (>= 0)'): 0.01,\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='solver', doc='The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto)'): 'auto',\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='standardization', doc='whether to standardize the training features before fitting the model'): True,\n",
       " Param(parent='LinearRegression_4ec4817545809e44dd6d', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters used\n",
    "bestLR = cvModel.bestModel\n",
    "bestLR.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the best features\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='label', aggregationDepth=2, maxIter=100, regParam=0.01, elasticNetParam=0.5, epsilon=1.35, fitIntercept = False, standardization = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(trainingPolyData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|label|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|10873.956538430633|194.0|(219,[0,1,2,3,4,5...|\n",
      "|10873.956538430633|248.0|(219,[0,1,2,3,4,5...|\n",
      "|10873.956538430633|267.0|(219,[0,1,2,3,4,5...|\n",
      "| 875.8916101522123|115.0|(219,[0,1,2,3,4,5...|\n",
      "| 875.8916101522123|118.0|(219,[0,1,2,3,4,5...|\n",
      "| 875.8916101522123|141.0|(219,[0,1,2,3,4,5...|\n",
      "| 875.8916101522123|141.0|(219,[0,1,2,3,4,5...|\n",
      "| 875.8916101522123|146.0|(219,[0,1,2,3,4,5...|\n",
      "| 875.8916101522123|166.0|(219,[0,1,2,3,4,5...|\n",
      "| 875.8916101522123|170.0|(219,[0,1,2,3,4,5...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make predictions\n",
    "lr_predictions = model.transform(testPolyData)\n",
    "lr_predictions.select(\"prediction\",\"label\",\"features\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on test data = 2.41071e+06\n"
     ]
    }
   ],
   "source": [
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"label\",metricName=\"mae\")\n",
    "mae = lr_evaluator.evaluate(lr_predictions)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on test data = 5.99599e+14\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"label\",metricName=\"mse\")\n",
    "mse = lr_evaluator.evaluate(lr_predictions)\n",
    "print(\"Mean Squared Error (MSE) on test data = %g\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2410706.7710912465"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599598500178390.9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24486700.475531425"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "rmse = math.sqrt(mse)\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
